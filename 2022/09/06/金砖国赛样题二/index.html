<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>金砖国赛样题二 | Misswjy&#39;Blog</title>

  <!-- keywords -->
  

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="2022金砖国家职业技能大赛样题B 场次题目：容器的编排与运维">
<meta property="og:type" content="article">
<meta property="og:title" content="金砖国赛样题二">
<meta property="og:url" content="http://example.com/2022/09/06/%E9%87%91%E7%A0%96%E5%9B%BD%E8%B5%9B%E6%A0%B7%E9%A2%98%E4%BA%8C/index.html">
<meta property="og:site_name" content="Misswjy&#39;Blog">
<meta property="og:description" content="2022金砖国家职业技能大赛样题B 场次题目：容器的编排与运维">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2022-09-06T01:23:05.000Z">
<meta property="article:modified_time" content="2022-10-30T12:40:14.000Z">
<meta property="article:author" content="Miss">
<meta property="article:tag" content="容器云">
<meta name="twitter:card" content="summary">
  
    <link rel="alternative" href="/atom.xml" title="Misswjy&#39;Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/img/favicon.ico">
  
  
<link rel="stylesheet" href="/css/style.css">

  
  

  
<script src="//cdn.bootcss.com/require.js/2.3.2/require.min.js"></script>

  
<script src="//cdn.bootcss.com/jquery/3.1.1/jquery.min.js"></script>


  
<meta name="generator" content="Hexo 6.1.0"></head>
<body>
  <div id="container">
    <div id="particles-js"></div>
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
				<img lazy-src="/img/avatar.png" class="js-avatar">
			
		</a>

		<hgroup>
			<h1 class="header-author"><a href="/">Miss</a></h1>
		</hgroup>

		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">Home</a></li>
				        
							<li><a href="/archives">Archives</a></li>
				        
						</ul>
					</nav>
					<nav class="half-header-menu">
						<a class="hide">Home</a>
						<a>Tags</a>
						<a>Links</a>
						<a>About</a>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/Misswjy" title="github">github</a>
					        
								<a class="mail" target="_blank" href="/dockery@foxmail.com" title="mail">mail</a>
					        
								<a class="bilibili" target="_blank" href="https://space.bilibili.com/292671654" title="bilibili">bilibili</a>
					        
						</div>
						<!-- music -->
						
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/k8s/" style="font-size: 15px;">k8s</a> <a href="/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/" style="font-size: 12.5px;">云计算</a> <a href="/tags/%E5%AE%B9%E5%99%A8%E4%BA%91/" style="font-size: 17.5px;">容器云</a> <a href="/tags/%E5%BA%94%E7%94%A8%E9%83%A8%E7%BD%B2%E5%92%8C%E8%BF%90%E7%BB%B4/" style="font-size: 10px;">应用部署和运维</a> <a href="/tags/%E7%A7%81%E6%9C%89%E4%BA%91/" style="font-size: 20px;">私有云</a>
					</div>
				</section>
				
				
				
				<section class="switch-part switch-part3">
					<div id="js-friends">
					
			          <a target="_blank" class="main-nav-link switch-friends-link" href="https://github.com/">github</a>
			        
			        </div>
				</section>
				

				
				
				<section class="switch-part switch-part4">
				
					<div id="js-aboutme">I&#39;m a developer.</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide"></h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img lazy-src="/img/avatar.png" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author"></h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">Home</a></li>
		        
					<li><a href="/archives">Archives</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/Misswjy" title="github">github</a>
			        
						<a class="mail" target="_blank" href="/dockery@foxmail.com" title="mail">mail</a>
			        
						<a class="bilibili" target="_blank" href="https://space.bilibili.com/292671654" title="bilibili">bilibili</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>
      <div class="body-wrap"><article id="post-金砖国赛样题二" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2022/09/06/%E9%87%91%E7%A0%96%E5%9B%BD%E8%B5%9B%E6%A0%B7%E9%A2%98%E4%BA%8C/" class="article-date">
  	<time datetime="2022-09-06T01:23:05.000Z" itemprop="datePublished">2022-09-06</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      金砖国赛样题二
      
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%AE%B9%E5%99%A8%E4%BA%91/" rel="tag">容器云</a></li></ul>
	</div>

        

        
        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="2022金砖国家职业技能大赛样题"><a href="#2022金砖国家职业技能大赛样题" class="headerlink" title="2022金砖国家职业技能大赛样题"></a>2022金砖国家职业技能大赛样题</h1><h2 id="B-场次题目：容器的编排与运维-gt"><a href="#B-场次题目：容器的编排与运维-gt" class="headerlink" title="B 场次题目：容器的编排与运维&gt;"></a>B 场次题目：容器的编排与运维<span id="more"></span>&gt;</h2><h3 id="任务-1-容器云平台环境初始化（5-分）"><a href="#任务-1-容器云平台环境初始化（5-分）" class="headerlink" title="任务 1 容器云平台环境初始化（5 分）"></a>任务 1 容器云平台环境初始化（5 分）</h3><p>1.容器云平台的初始化 根据表 2 的 IP 地址规划，创建云服务器，镜像使用 CentOS_7.5_x86_64_XD. qcow，确保网络正常通信。按照表 2 置主机名节点并关闭 swap，同时永久关闭 s elinux 以及防火墙,并修改 hosts 映射。 请将 master 节点 hosts 文件内容提交到答题框。【1 分】</p>
<p><strong>主机名节点并关闭 swap</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# swapoff -a</span><br></pre></td></tr></table></figure>

<p><strong>永久关闭 s elinux 以及防火墙</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# setenforce 0</span><br><span class="line">setenforce: SELinux is disabled</span><br><span class="line">[root@master ~]# cat /etc/selinux/config </span><br><span class="line"></span><br><span class="line"># This file controls the state of SELinux on the system.</span><br><span class="line"></span><br><span class="line"># SELINUX= can take one of these three values:</span><br><span class="line"></span><br><span class="line">#     enforcing - SELinux security policy is enforced.</span><br><span class="line"></span><br><span class="line">#     permissive - SELinux prints warnings instead of enforcing.</span><br><span class="line"></span><br><span class="line">#     disabled - No SELinux policy is loaded.</span><br><span class="line"></span><br><span class="line">SELINUX=disabled</span><br><span class="line"></span><br><span class="line"># SELINUXTYPE= can take one of three two values:</span><br><span class="line"></span><br><span class="line">#     targeted - Targeted processes are protected,</span><br><span class="line"></span><br><span class="line">#     minimum - Modification of targeted policy. Only selected processes are protected. </span><br><span class="line"></span><br><span class="line">#     mls - Multi Level Security protection.</span><br><span class="line"></span><br><span class="line">SELINUXTYPE=targeted</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>修改 hosts 映射</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# cat /etc/hosts</span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line"></span><br><span class="line">192.168.20.115	master</span><br><span class="line">192.168.20.122	node1</span><br><span class="line">192.168.20.112	node2</span><br><span class="line">192.168.20.114	harbor</span><br></pre></td></tr></table></figure>

<p>2．Yum 源数据的持久化挂载 将提供的 CentOS-7-x86_64-DVD-1804.iso 和 chinaskills_cloud_paas.iso 光盘镜像上传到 master 节点 &#x2F;root 目录下，然后在 &#x2F;opt 目录下使用命令创建 &#x2F;centos 目录和 &#x2F;paas 目录，并将镜像文件 CentOS-7-x86_64-DVD-1804.iso 挂 载到&#x2F;centos 目录下，将镜像文件 chinaskills_cloud_paas.iso 挂载到 &#x2F;paas 目录下。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# curl -O http://172.19.25.11/middle/chinaskills_cloud_paas.iso</span><br><span class="line">  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line">100 8825M  100 8825M    0     0   111M      0  0:01:19  0:01:19 --:--:--  111M</span><br><span class="line">[root@master ~]# curl -O http://172.19.25.11/middle/CentOS-7-x86_64-DVD-1804.iso</span><br><span class="line">  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line">100 4263M  100 4263M    0     0   111M      0  0:00:38  0:00:38 --:--:--  106M</span><br><span class="line">[root@master ~]# mount chinaskills_cloud_paas.iso /mnt/</span><br><span class="line">mount: /dev/loop0 is write-protected, mounting read-only</span><br><span class="line">[root@master ~]# mkdir -p /opt/paas</span><br><span class="line">[root@master ~]# mkdir -p /opt/centos</span><br><span class="line">[root@master ~]# cp -rf /mnt/* /opt/paas/</span><br><span class="line">[root@master ~]# umount /mnt/</span><br><span class="line">[root@master ~]# mount CentOS-7-x86_64-DVD-1804.iso /mnt/</span><br><span class="line">mount: /dev/loop0 is write-protected, mounting read-only</span><br><span class="line">[root@master ~]# cp -rf /mnt/* /opt/centos/</span><br><span class="line">[root@master ~]# umount /mnt/</span><br></pre></td></tr></table></figure>

<p>3．Yum 源的编写 为 master 节点设置本地 yum 源，yum 源文件名为 centos.repo，安装 ftp 服 务，将 ftp 仓库设置为 &#x2F;opt&#x2F;，为其他节点配置 ftp 源，yum 源文件名称为 ftp. repo，其中 ftp 服务器地址为 master 节点 IP。 请将其它节点的 yum 源文件内容提交到答题框。【1 分】</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# cat /etc/yum.repos.d/local.repo </span><br><span class="line">[centos]</span><br><span class="line">name=centos</span><br><span class="line">baseurl=file:///opt/centos/</span><br><span class="line">gpgcheck=0</span><br><span class="line">enabled=1</span><br><span class="line"></span><br><span class="line">[k8s]</span><br><span class="line">name=k8s</span><br><span class="line">baseurl=file:///opt/paas/kubernetes-repo</span><br><span class="line">gpgcheck=0</span><br><span class="line">enabled=1</span><br><span class="line">[root@master ~]# yum install -y vsftpd</span><br><span class="line">[root@master ~]# echo &quot;anon_root=/opt/&quot; &gt;&gt; /etc/vsftpd/vsftpd.conf </span><br><span class="line">[root@master ~]# systemctl restart vsftpd</span><br><span class="line">[root@master ~]# systemctl enable vsftpd</span><br><span class="line">Created symlink from /etc/systemd/system/multi-user.target.wants/vsftpd.service to /usr/lib/systemd/system/vsftpd.service.</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# cat /etc/yum.repos.d/ftp.repo </span><br><span class="line">[centos]</span><br><span class="line">name=centos</span><br><span class="line">baseurl=ftp://master/centos/</span><br><span class="line">gpgcheck=0</span><br><span class="line">enabled=1</span><br><span class="line"></span><br><span class="line">[k8s]</span><br><span class="line">name=k8s</span><br><span class="line">baseurl=ftp://master/paas/kubernetes-repo</span><br><span class="line">gpgcheck=0</span><br><span class="line">enabled=1</span><br></pre></td></tr></table></figure>

<p>4．设置时间同步服务器 在 master 节点上部署 chrony 服务器，允许其他节点同步时间，启动服务并 设置为开机启动；在其他节点上指定 master 节点为上游 NTP 服务器，重启服务 并设为开机启动。 请在 master 节点上使用 chronyc 命令同步控制节点的系统时间。</p>
<p><strong>master 节点</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# cat /etc/chrony.conf </span><br><span class="line"></span><br><span class="line"># Use public servers from the pool.ntp.org project.</span><br><span class="line"></span><br><span class="line"># Please consider joining the pool (http://www.pool.ntp.org/join.html).</span><br><span class="line"></span><br><span class="line">#server 0.centos.pool.ntp.org iburst</span><br><span class="line">#server 1.centos.pool.ntp.org iburst</span><br><span class="line">#server 2.centos.pool.ntp.org iburst</span><br><span class="line">#server 3.centos.pool.ntp.org iburst</span><br><span class="line">server	master	iburst</span><br><span class="line"></span><br><span class="line"># Record the rate at which the system clock gains/losses time.</span><br><span class="line"></span><br><span class="line">driftfile /var/lib/chrony/drift</span><br><span class="line"></span><br><span class="line"># Allow the system clock to be stepped in the first three updates</span><br><span class="line"></span><br><span class="line"># if its offset is larger than 1 second.</span><br><span class="line"></span><br><span class="line">makestep 1.0 3</span><br><span class="line"></span><br><span class="line"># Enable kernel synchronization of the real-time clock (RTC).</span><br><span class="line"></span><br><span class="line">rtcsync</span><br><span class="line"></span><br><span class="line"># Enable hardware timestamping on all interfaces that support it.</span><br><span class="line"></span><br><span class="line">#hwtimestamp *</span><br><span class="line"></span><br><span class="line"># Increase the minimum number of selectable sources required to adjust</span><br><span class="line"></span><br><span class="line"># the system clock.</span><br><span class="line"></span><br><span class="line">#minsources 2</span><br><span class="line"></span><br><span class="line"># Allow NTP client access from local network.</span><br><span class="line"></span><br><span class="line">#allow 192.168.0.0/16</span><br><span class="line"></span><br><span class="line"># Serve time even if not synchronized to a time source.</span><br><span class="line"></span><br><span class="line">#local stratum 10</span><br><span class="line"></span><br><span class="line"># Specify file containing keys for NTP authentication.</span><br><span class="line"></span><br><span class="line">#keyfile /etc/chrony.keys</span><br><span class="line"></span><br><span class="line"># Specify directory for log files.</span><br><span class="line"></span><br><span class="line">logdir /var/log/chrony</span><br><span class="line"></span><br><span class="line"># Select which information is logged.</span><br><span class="line"></span><br><span class="line">#log measurements statistics tracking</span><br><span class="line">allow 192.168.20.0/24</span><br><span class="line">local stratum 10</span><br></pre></td></tr></table></figure>

<p><strong>node节点</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# cat /etc/chrony.conf </span><br><span class="line"></span><br><span class="line"># Use public servers from the pool.ntp.org project.</span><br><span class="line"></span><br><span class="line"># Please consider joining the pool (http://www.pool.ntp.org/join.html).</span><br><span class="line"></span><br><span class="line">#server 0.centos.pool.ntp.org iburst</span><br><span class="line">#server 1.centos.pool.ntp.org iburst</span><br><span class="line">#server 2.centos.pool.ntp.org iburst</span><br><span class="line">#server 3.centos.pool.ntp.org iburst</span><br><span class="line">server	master	iburst</span><br><span class="line"></span><br><span class="line"># Record the rate at which the system clock gains/losses time.</span><br><span class="line"></span><br><span class="line">driftfile /var/lib/chrony/drift</span><br><span class="line"></span><br><span class="line"># Allow the system clock to be stepped in the first three updates</span><br><span class="line"></span><br><span class="line"># if its offset is larger than 1 second.</span><br><span class="line"></span><br><span class="line">makestep 1.0 3</span><br><span class="line"></span><br><span class="line"># Enable kernel synchronization of the real-time clock (RTC).</span><br><span class="line"></span><br><span class="line">rtcsync</span><br><span class="line"></span><br><span class="line"># Enable hardware timestamping on all interfaces that support it.</span><br><span class="line"></span><br><span class="line">#hwtimestamp *</span><br><span class="line"></span><br><span class="line"># Increase the minimum number of selectable sources required to adjust</span><br><span class="line"></span><br><span class="line"># the system clock.</span><br><span class="line"></span><br><span class="line">#minsources 2</span><br><span class="line"></span><br><span class="line"># Allow NTP client access from local network.</span><br><span class="line"></span><br><span class="line">#allow 192.168.0.0/16</span><br><span class="line"></span><br><span class="line"># Serve time even if not synchronized to a time source.</span><br><span class="line"></span><br><span class="line">#local stratum 10</span><br><span class="line"></span><br><span class="line"># Specify file containing keys for NTP authentication.</span><br><span class="line"></span><br><span class="line">#keyfile /etc/chrony.keys</span><br><span class="line"></span><br><span class="line"># Specify directory for log files.</span><br><span class="line"></span><br><span class="line">logdir /var/log/chrony</span><br><span class="line"></span><br><span class="line"># Select which information is logged.</span><br><span class="line"></span><br><span class="line">#log measurements statistics tracking</span><br></pre></td></tr></table></figure>

<p>5.设置免密登录 为四台服务器设置免密登录，保证 3 台服务器能够互相免密登录。请使用 s cp 命令将 master 节点的 hosts 文件发送到所有节点的 &#x2F;etc&#x2F;hosts。将以上所 有命令和返回结果提交到答题框。【1 分】</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# ssh-keygen </span><br><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter file in which to save the key (/root/.ssh/id_rsa): </span><br><span class="line">/root/.ssh/id_rsa already exists.</span><br><span class="line">Overwrite (y/n)? </span><br><span class="line">[root@master ~]# ssh-copy-id node1</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;/root/.ssh/id_rsa.pub&quot;</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed</span><br><span class="line"></span><br><span class="line">/usr/bin/ssh-copy-id: WARNING: All keys were skipped because they already exist on the remote system.</span><br><span class="line">		(if you think this is a mistake, you may want to use -f option)</span><br><span class="line"></span><br><span class="line">[root@master ~]# ssh-copy-id node2</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;/root/.ssh/id_rsa.pub&quot;</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed</span><br><span class="line"></span><br><span class="line">/usr/bin/ssh-copy-id: WARNING: All keys were skipped because they already exist on the remote system.</span><br><span class="line">		(if you think this is a mistake, you may want to use -f option)</span><br><span class="line"></span><br><span class="line">[root@master ~]# ssh-copy-id harbor</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;/root/.ssh/id_rsa.pub&quot;</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed</span><br><span class="line"></span><br><span class="line">/usr/bin/ssh-copy-id: WARNING: All keys were skipped because they already exist on the remote system.</span><br><span class="line">		(if you think this is a mistake, you may want to use -f option)</span><br></pre></td></tr></table></figure>

<h3 id="任务-2-Kubernetes-搭建任务（10-分）"><a href="#任务-2-Kubernetes-搭建任务（10-分）" class="headerlink" title="任务 2 Kubernetes 搭建任务（10 分）"></a>任务 2 Kubernetes 搭建任务（10 分）</h3><p>1.安装 docker 应用 在所有节点上安装 dokcer-ce。并在 harbor 节点安装 harbor 仓库，显现正 常登录 horbor 仓库，登录密码设置为“test_工位号”。请将登录后截图提交到 答题框。【1 分】</p>
<p><strong>所有节点</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# yum install -y yum-utils device-mapper-p* lvm2</span><br><span class="line">[root@master ~]# yum  install -y docker-ce</span><br><span class="line">[root@master ~]# systemctl restart docker</span><br><span class="line">[root@master ~]# systemctl enable docker</span><br></pre></td></tr></table></figure>

<p><strong>harbor节点</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/harbor/</span><br><span class="line">tar -zxvf harbor-offline-installer-v2.1.0.tgz</span><br><span class="line">cd harbor</span><br><span class="line">mv harbor.yml.tmpl harbor.yml</span><br><span class="line">sed -i &quot;5s/reg.mydomain.com/$&#123;IP&#125;/g&quot; harbor.yml</span><br><span class="line">sed -i &quot;13s/^/#/g&quot; harbor.yml</span><br><span class="line">sed -i &quot;15,18s/^/#/g&quot; harbor.yml</span><br><span class="line">./prepare || exit</span><br><span class="line">./install.sh --with-clair || exit</span><br></pre></td></tr></table></figure>

<p>2.搭建 horbor 仓库 修改默认 docker 仓库为 horbor 地址，修改 docker 启动引擎为 systemd。 安装完成后执行 docker verison 命令返回结果以及将 daemon.json 文件内容提 交。【2 分】</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# cat /etc/docker/daemon.json </span><br><span class="line">&#123;</span><br><span class="line"> &quot;insecure-registries&quot;:[&quot;192.168.20.114&quot;],</span><br><span class="line">  &quot;exec-opts&quot;:[&quot;native.cgroupdriver=systemd&quot;]</span><br><span class="line">&#125;</span><br><span class="line">[root@master ~]# systemctl restart docker</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# docker version</span><br><span class="line">Client: Docker Engine - Community</span><br><span class="line"> Version:           19.03.13</span><br><span class="line"> API version:       1.40</span><br><span class="line"> Go version:        go1.13.15</span><br><span class="line"> Git commit:        4484c46d9d</span><br><span class="line"> Built:             Wed Sep 16 17:03:45 2020</span><br><span class="line"> OS/Arch:           linux/amd64</span><br><span class="line"> Experimental:      false</span><br><span class="line"></span><br><span class="line">Server: Docker Engine - Community</span><br><span class="line"> Engine:</span><br><span class="line">  Version:          19.03.13</span><br><span class="line">  API version:      1.40 (minimum version 1.12)</span><br><span class="line">  Go version:       go1.13.15</span><br><span class="line">  Git commit:       4484c46d9d</span><br><span class="line">  Built:            Wed Sep 16 17:02:21 2020</span><br><span class="line">  OS/Arch:          linux/amd64</span><br><span class="line">  Experimental:     false</span><br><span class="line"> containerd:</span><br><span class="line">  Version:          1.3.7</span><br><span class="line">  GitCommit:        8fba4e9a7d01810a393d5d25a3621dc101981175</span><br><span class="line"> runc:</span><br><span class="line">  Version:          1.0.0-rc10</span><br><span class="line">  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd</span><br><span class="line"> docker-init:</span><br><span class="line">  Version:          0.18.0</span><br><span class="line">  GitCommit:        fec3683</span><br></pre></td></tr></table></figure>

<p>3.安装 docker-compose 在 master 节点上使用 &#x2F;opt&#x2F;paas&#x2F;docker-compose&#x2F;v1.25.5-docker-compo se-Linux-x86_6 下的文件安装 docker-compose。安装完成后执行 docker-compose version 命令，请将程序返回结果提交到答题框。【0.5 分】</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# mv /opt/paas/docker-compose/v1.25.5-docker-compose-Linux-x86_64 /usr/local/bin/docker-compose</span><br><span class="line">[root@master ~]# docker-compose version</span><br><span class="line">docker-compose version 1.25.5, build 8a1c60f6</span><br><span class="line">docker-py version: 4.1.0</span><br><span class="line">CPython version: 3.7.5</span><br><span class="line">OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019</span><br></pre></td></tr></table></figure>

<p>4.上传 docker 镜像 在 master 节点使用 &#x2F;opt&#x2F;paas&#x2F; k8s_image_push.sh 将所有镜像上传至 do cker 仓库。完成后将 Harbor 仓库 library 中镜像列表截图，请将以上截图提交 到答题框。【1 分】</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# for i in $(ls /opt/paas/images/); do docker load -i /opt/paas/images/$i; done</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master paas]# ./k8s_image_push.sh </span><br></pre></td></tr></table></figure>

<p>5.安装 kubeadm 工具 在 master 及 node 节点安装 Kubeadm 工具并设置开机自动启动，安装完成后 使用 rpm 命令配合 grep 查看 Kubeadm 工具是否正确安装。将 rpm 命令配合 grep 返回结果提交到答题框。【0.5 分】</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@master paas]# yum install -y kubelet-1.18.1 kubeadm-1.18.1 kubectl-1.18.1</span><br><span class="line">[root@master paas]# systemctl enable kubelet</span><br><span class="line">Created symlink from /etc/systemd/system/multi-user.target.wants/kubelet.service to /usr/lib/systemd/system/kubelet.service.</span><br><span class="line">[root@master paas]# systemctl restart kubelet</span><br><span class="line">[root@master paas]# rpm -qa | grep kubeadm</span><br><span class="line">kubeadm-1.18.1-0.x86_64</span><br></pre></td></tr></table></figure>

<p>6.计算节点获取必备镜像 在所有 node 节点中使用 docker 命令拉取安装 kubernetes 基础镜像，拉取 完成后使用 docker 命令查看镜像列表。【1 分】</p>
<p>7.kubeadm 安装 master 使用 kubeadm 命令初始化 master 节点，设置 kubernetes 虚拟内部网段地址 为 10.244.0.0&#x2F;16，然后使用 kube-flannel.yaml 完成控制节点初始化设置，完 成后使用命令查看集群状态和所有 pod。 将以上命令和返回结果提交到答题框。【2 分】</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# modprobe br_netfilter</span><br><span class="line">[root@master ~]# echo &quot;net.ipv4.ip_forward = 1&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line">[root@master ~]# echo &quot;net.bridge.bridge-nf-call-ip6tables = 1&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line">[root@master ~]# echo &quot;net.bridge.bridge-nf-call-iptables = 1&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line">[root@master ~]# sysctl -p</span><br><span class="line">[root@master ~]# kubeadm init --kubernetes-version=1.18.1 --apiserver-advertise-address=192.168.20.115 --image-repository 192.168.20.114/library --pod-network-cidr=10.244.0.0/16</span><br><span class="line">[root@master ~]# mkdir -p /root/.kube</span><br><span class="line">[root@master ~]# cp -i /etc/kubernetes/admin.conf /root/.kube/config</span><br><span class="line">[root@master ~]# chown $(id -u):$(id -g) /root/.kube/config </span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# sed -i &#x27;s/quay.io\/coreos/192.168.20.114\/library/g&#x27; /opt/paas/yaml/flannel/kube-flannel.yaml </span><br><span class="line">[root@master ~]# kubectl apply -f /opt/paas/yaml/flannel/kube-flannel.yaml </span><br><span class="line">podsecuritypolicy.policy/psp.flannel.unprivileged created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/flannel created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/flannel created</span><br><span class="line">serviceaccount/flannel created</span><br><span class="line">configmap/kube-flannel-cfg created</span><br><span class="line">daemonset.apps/kube-flannel-ds created</span><br><span class="line">[root@master ~]# kubectl get pod --all-namespaces</span><br><span class="line">NAMESPACE     NAME                             READY   STATUS    RESTARTS   AGE</span><br><span class="line">kube-system   coredns-f8789844f-5v894          1/1     Running   0          7m54s</span><br><span class="line">kube-system   coredns-f8789844f-vfh6t          1/1     Running   0          7m54s</span><br><span class="line">kube-system   etcd-master                      1/1     Running   0          8m7s</span><br><span class="line">kube-system   kube-apiserver-master            1/1     Running   0          8m7s</span><br><span class="line">kube-system   kube-controller-manager-master   1/1     Running   0          8m7s</span><br><span class="line">kube-system   kube-flannel-ds-xvn9p            1/1     Running   0          43s</span><br><span class="line">kube-system   kube-proxy-fjkd2                 1/1     Running   0          7m54s</span><br><span class="line">kube-system   kube-scheduler-master            1/1     Running   0          8m7s</span><br></pre></td></tr></table></figure>

<p>8.安装 kubernetes 网络插件 使用 kube-flannel.yaml 安装 kubernetes 网络插件，安装完成后使用命令 查看节点状态。完成后使用命令查看集群状态。将集群状态查看命令和返回结果 提交到答题框。【0.5 分】</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# kubectl get nodes</span><br><span class="line">NAME     STATUS   ROLES    AGE   VERSION</span><br><span class="line">master   Ready    master   10m   v1.18.1</span><br><span class="line">[root@master ~]# kubectl cluster-info</span><br><span class="line">Kubernetes master is running at https://192.168.20.115:6443</span><br><span class="line">KubeDNS is running at https://192.168.20.115:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</span><br><span class="line"></span><br><span class="line">To further debug and diagnose cluster problems, use &#x27;kubectl cluster-info dump&#x27;.</span><br></pre></td></tr></table></figure>

<p>9.kubernetes 图形化界面的安装 安装 kubernetes dashboard 界面，完成后查看首页然后将 kubernetes dashboard 界面截图提交到答题框。【1 分】</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mkdir dashboard-certs</span><br><span class="line">cd dashboard-certs/</span><br><span class="line">kubectl create namespace kubernetes-dashboard</span><br><span class="line">openssl genrsa -out dashboard.key 2048</span><br><span class="line">openssl req -days 36000 -new -out dashboard.csr -key dashboard.key -subj &#x27;/CN=dashboard-cert&#x27;</span><br><span class="line">openssl x509 -req -in dashboard.csr -signkey dashboard.key -out dashboard.crt</span><br><span class="line">kubectl create secret generic kubernetes-dashboard-certs --from-file=dashboard.key --from-file=dashboard.crt -n kubernetes-dashboard</span><br><span class="line">sed -i &quot;s/kubernetesui/$IP\/library/g&quot; /opt/yaml/dashboard/recommended.yaml </span><br><span class="line">kubectl apply -f /opt/yaml/dashboard/recommended.yaml </span><br><span class="line">kubectl apply -f /opt/yaml/dashboard/dashboard-adminuser.yaml</span><br></pre></td></tr></table></figure>

<p>10.扩展计算节点 在 master 节点上使用 kubeadm 命令查看 token，在所有 node 节点上使用 k ubeadm 命令将 node 节点加入 kubernetes 集群。完成后在 master 节点上查看所 有节点状态。</p>
<p><strong>所有node节点</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">modprobe br_netfilter</span><br><span class="line">cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; EOF</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">EOF</span><br><span class="line">sysctl -p /etc/sysctl.d/k8s.conf</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# cat /etc/docker/daemon.json </span><br><span class="line">&#123;</span><br><span class="line"> &quot;insecure-registries&quot;:[&quot;192.168.20.114&quot;],</span><br><span class="line">  &quot;exec-opts&quot;:[&quot;native.cgroupdriver=systemd&quot;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ssh master &quot;kubeadm token create --print-join-command&quot; &gt;token.sh</span><br><span class="line">chmod +x token.sh &amp;&amp; source token.sh &amp;&amp; rm -rf token.sh</span><br><span class="line">sleep 20</span><br><span class="line">ssh master &quot;kubectl get nodes&quot;</span><br></pre></td></tr></table></figure>

<h3 id="任务-3-Kubernetes-运维任务（15-分）"><a href="#任务-3-Kubernetes-运维任务（15-分）" class="headerlink" title="任务 3 Kubernetes 运维任务（15 分）"></a>任务 3 Kubernetes 运维任务（15 分）</h3><p>1.使用 dockerfile 构建 dokcer 镜像  以 mysql:5.7 镜像为基础镜像，制作一个 mysql 镜像，可以将提供的 sql 文 件初始化到mysql数据库中，然后使用编写的dockerfile文件将镜像制作出来， 名称为 mysql:latest，并将该镜像上传至前面所搭建的 harbor 仓库中，编写 Y AML 文件，验证数据库内容。 完成后将 dockerfile 文件内容及 harbor 仓库镜像列表、数据库内容提交到 答题框。【1 分】</p>
<p>2.持久化存储 搭建 NFS 共享存储，配置 nfs-provisioner，创建 storageclass，通过 storageclass 动态生成 pvc，大小为 1Gi，修改标准 nfs-deployment.yaml 文件， 编写 storageclass.yaml 和 pvc.yaml 文件，将最终 pvc 状态截图和 yaml 文件提 交至答题框。【2 分】</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# yum install -y nfs-utils rpcbind</span><br><span class="line">[root@master ~]# cat /etc/exports</span><br><span class="line">/root/nfs *(rw,async,no_root_squash)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# cat rpac.yaml </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs-client-provisioner</span><br><span class="line"></span><br><span class="line">  # replace with namespace where provisioner is deployed</span><br><span class="line"></span><br><span class="line">  namespace: default        #根据实际环境设定namespace,下面类同</span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">kind: ClusterRole</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs-client-provisioner-runner</span><br><span class="line">rules:</span><br><span class="line"></span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;persistentvolumes&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;delete&quot;]</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;persistentvolumeclaims&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;update&quot;]</span><br><span class="line">  - apiGroups: [&quot;storage.k8s.io&quot;]</span><br><span class="line">    resources: [&quot;storageclasses&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;events&quot;]</span><br><span class="line">    verbs: [&quot;create&quot;, &quot;update&quot;, &quot;patch&quot;]</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: run-nfs-client-provisioner</span><br><span class="line">subjects:</span><br><span class="line"></span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: nfs-client-provisioner</span><br><span class="line"></span><br><span class="line">    # replace with namespace where provisioner is deployed</span><br><span class="line"></span><br><span class="line">    namespace: default</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: nfs-client-provisioner-runner</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">kind: Role</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: leader-locking-nfs-client-provisioner</span><br><span class="line"></span><br><span class="line">  # replace with namespace where provisioner is deployed</span><br><span class="line"></span><br><span class="line">  namespace: default</span><br><span class="line">rules:</span><br><span class="line"></span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;endpoints&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;]</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">kind: RoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: leader-locking-nfs-client-provisioner</span><br><span class="line">subjects:</span><br><span class="line"></span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: nfs-client-provisioner</span><br><span class="line"></span><br><span class="line">    # replace with namespace where provisioner is deployed</span><br><span class="line"></span><br><span class="line">    namespace: default</span><br><span class="line">roleRef:</span><br><span class="line">  kind: Role</span><br><span class="line">  name: leader-locking-nfs-client-provisioner</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# cat storageclass.yaml </span><br><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">kind: StorageClass</span><br><span class="line">metadata:</span><br><span class="line">  name: managed-nfs-storage</span><br><span class="line">provisioner: nfs-storage #这里的名称要和provisioner配置文件中的环境变量PROVISIONER_NAME保持一致</span><br><span class="line">parameters:</span><br><span class="line">  archiveOnDelete: &quot;false&quot;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# cat nfs-deployment.yaml </span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs-client-provisioner</span><br><span class="line">  labels:</span><br><span class="line">    app: nfs-client-provisioner</span><br><span class="line"></span><br><span class="line">  # replace with namespace where provisioner is deployed</span><br><span class="line"></span><br><span class="line">    namespace: default  #与RBAC文件中的namespace保持一致</span><br><span class="line"></span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  strategy:</span><br><span class="line">    type: Recreate</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nfs-client-provisioner</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nfs-client-provisioner</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: nfs-client-provisioner</span><br><span class="line">      containers:</span><br><span class="line">        - name: nfs-client-provisioner</span><br><span class="line">          image: 192.168.20.114/library/nfs-client-provisioner:latest</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: nfs-client-root</span><br><span class="line">              mountPath: /persistentvolumes</span><br><span class="line">          env:</span><br><span class="line">            - name: PROVISIONER_NAME</span><br><span class="line">              value: nfs-storage  #provisioner名称,请确保该名称与 nfs-StorageClass.yaml文件中的provisioner名称保持一致</span><br><span class="line">            - name: NFS_SERVER</span><br><span class="line">              value: 192.168.20.115   #NFS Server IP地址</span><br><span class="line">            - name: NFS_PATH  </span><br><span class="line">              value: /root/nfs    #NFS挂载卷</span><br><span class="line">      volumes:</span><br><span class="line">        - name: nfs-client-root</span><br><span class="line">          nfs:</span><br><span class="line">            server: 192.168.20.115  #NFS Server IP地址</span><br><span class="line">            path: /root/nfs     #NFS 挂载卷</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# cat pvc.yaml </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: test-pvc</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteMany</span><br><span class="line">  storageClassName: managed-nfs-storage # StorageClass</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 1Gi</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# kubectl apply -f rpac.yaml </span><br><span class="line">[root@master ~]# kubectl apply -f storageclass.yaml</span><br><span class="line">[root@master ~]# kubectl apply -f nfs-deployment.yaml </span><br><span class="line">[root@master ~]# kubectl apply -f pvc.yaml </span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# kubectl get pod,sc,pvc,pv</span><br><span class="line">NAME                                        READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/nfs-client-provisioner-8d5b467d-cr7qw   1/1     Running   0          15m</span><br><span class="line"></span><br><span class="line">NAME                                              PROVISIONER   RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE</span><br><span class="line">storageclass.storage.k8s.io/managed-nfs-storage   nfs-storage   Delete          Immediate           false                  27m</span><br><span class="line"></span><br><span class="line">NAME                             STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS          AGE</span><br><span class="line">persistentvolumeclaim/test-pvc   Bound    pvc-ee59105c-cc95-48ac-af39-75ab6ca51ac0   1Gi        RWX            managed-nfs-storage   2m24s</span><br><span class="line"></span><br><span class="line">NAME                                                        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM              STORAGECLASS          REASON   AGE</span><br><span class="line">persistentvolume/pvc-ee59105c-cc95-48ac-af39-75ab6ca51ac0   1Gi        RWX            Delete           Bound    default/test-pvc   managed-nfs-storage            2m24s</span><br></pre></td></tr></table></figure>

<p>3.编写 deployment 文件 将提供的 nginx:latest 镜像上传至 harbor 镜像仓库，使用该镜像编写 dep loyment 文件，要求将已创建的 pvc 挂载至&#x2F;html 目录下，副本数 1，实现资源 限制:需求内存 300Mi，需求 CPU 300M，限制内存 450Mi，限制 CPU450M，将 POD 状态截图和 yaml 文件提交至答题框。【3 分】</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# cat nginx-deployment.yaml </span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  creationTimestamp: null</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx</span><br><span class="line">  name: nginx</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx</span><br><span class="line">  strategy: &#123;&#125;</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      creationTimestamp: null</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: 192.168.20.114/library/nginx:latest</span><br><span class="line">        name: nginx</span><br><span class="line">        ports:</span><br><span class="line">          - name: nginx-port</span><br><span class="line">            containerPort: 80</span><br><span class="line">        volumeMounts:</span><br><span class="line">          - name: test-pvc</span><br><span class="line">            mountPath: /usr/share/nginx/html</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            cpu: 450m</span><br><span class="line">            memory: 450Mi</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 300m</span><br><span class="line">            memory: 300Mi</span><br><span class="line">      volumes:</span><br><span class="line">        - name: test-pvc</span><br><span class="line">          persistentVolumeClaim:</span><br><span class="line">            claimName: test-pvc</span><br></pre></td></tr></table></figure>

<p>4.创建 service 服务，提供对外访问接口 基于 nginx 的 pod 服务，编写一个 service 名称为 nginx-svc，代理 nginx 的服务端口，端口类型为 nodeport，创建成功后可以通过该 service 访问 nginx。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# cat nginx-svc.yaml </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx</span><br><span class="line">  name: nginx-svc</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">    name: nginx-port   </span><br><span class="line">  selector:</span><br><span class="line">    app: nginx</span><br><span class="line">  type: NodePort</span><br></pre></td></tr></table></figure>

<p>5.配置 metrics-server 实现资源监控 将已提供的 metrics-server 镜像上传至 harbor，修改 components.yaml， 创建 metrics-server，完成后，将 metrics-server 状态截图提交至答题框。【2 分】</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# cat components.yaml </span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  name: system:aggregated-metrics-reader</span><br><span class="line">  labels:</span><br><span class="line">    rbac.authorization.k8s.io/aggregate-to-view: &quot;true&quot;</span><br><span class="line">    rbac.authorization.k8s.io/aggregate-to-edit: &quot;true&quot;</span><br><span class="line">    rbac.authorization.k8s.io/aggregate-to-admin: &quot;true&quot;</span><br><span class="line">rules:</span><br><span class="line"></span><br><span class="line">- apiGroups: [&quot;metrics.k8s.io&quot;]</span><br><span class="line">  resources: [&quot;pods&quot;, &quot;nodes&quot;]</span><br><span class="line">  verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: metrics-server:system:auth-delegator</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:auth-delegator</span><br><span class="line">subjects:</span><br><span class="line"></span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: RoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: metrics-server-auth-reader</span><br><span class="line">  namespace: kube-system</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Role</span><br><span class="line">  name: extension-apiserver-authentication-reader</span><br><span class="line">subjects:</span><br><span class="line"></span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: apiregistration.k8s.io/v1beta1</span><br><span class="line">kind: APIService</span><br><span class="line">metadata:</span><br><span class="line">  name: v1beta1.metrics.k8s.io</span><br><span class="line">spec:</span><br><span class="line">  service:</span><br><span class="line">    name: metrics-server</span><br><span class="line">    namespace: kube-system</span><br><span class="line">  group: metrics.k8s.io</span><br><span class="line">  version: v1beta1</span><br><span class="line">  insecureSkipTLSVerify: true</span><br><span class="line">  groupPriorityMinimum: 100</span><br><span class="line"></span><br><span class="line">  versionPriority: 100</span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: metrics-server</span><br><span class="line"></span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: metrics-server</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: metrics-server</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: metrics-server</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: metrics-server</span><br><span class="line">      volumes:</span><br><span class="line">      # mount in tmp so we can safely use from-scratch images and/or read-only containers</span><br><span class="line">      - name: tmp-dir</span><br><span class="line">        emptyDir: &#123;&#125;</span><br><span class="line">      containers:</span><br><span class="line">      - name: metrics-server</span><br><span class="line">        image: 192.168.20.114/library/metrics-server-amd64:v0.3.6</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        args:</span><br><span class="line">          - --cert-dir=/tmp</span><br><span class="line">          - --secure-port=4443</span><br><span class="line">        ports:</span><br><span class="line">        - name: main-port</span><br><span class="line">          containerPort: 4443</span><br><span class="line">          protocol: TCP</span><br><span class="line">        command:</span><br><span class="line">        - /metrics-server</span><br><span class="line">        - --kubelet-insecure-tls</span><br><span class="line">        - --kubelet-preferred-address-types=InternalDNS,InternalIP,ExternalDNS,ExternalIP,Hostname</span><br><span class="line">        securityContext:</span><br><span class="line">          readOnlyRootFilesystem: true</span><br><span class="line">          runAsNonRoot: true</span><br><span class="line">          runAsUser: 1000</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: tmp-dir</span><br><span class="line">          mountPath: /tmp</span><br><span class="line">      #nodeSelector:</span><br><span class="line">        #kubernetes.io/os: linux</span><br><span class="line">        #kubernetes.io/arch: &quot;amd64&quot;</span><br><span class="line"></span><br><span class="line">      nodeName: master</span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io/name: &quot;Metrics-server&quot;</span><br><span class="line">    kubernetes.io/cluster-service: &quot;true&quot;</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">  ports:</span><br><span class="line"></span><br><span class="line">  - port: 443</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: main-port</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  name: system:metrics-server</span><br><span class="line">rules:</span><br><span class="line"></span><br><span class="line">- apiGroups:</span><br><span class="line">  - &quot;&quot;</span><br><span class="line">  resources:</span><br><span class="line">  - pods</span><br><span class="line">  - nodes</span><br><span class="line">  - nodes/stats</span><br><span class="line">  - namespaces</span><br><span class="line">  - configmaps</span><br><span class="line">  verbs:</span><br><span class="line">  - get</span><br><span class="line">  - list</span><br><span class="line">  - watch</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: system:metrics-server</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:metrics-server</span><br><span class="line">subjects:</span><br><span class="line"></span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# kubectl apply -f components.yaml </span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# kubectl get apiservice</span><br><span class="line">NAME                                   SERVICE                      AVAILABLE   AGE</span><br><span class="line">v1.                                    Local                        True        25h</span><br><span class="line">v1.admissionregistration.k8s.io        Local                        True        25h</span><br><span class="line">v1.apiextensions.k8s.io                Local                        True        25h</span><br><span class="line">v1.apps                                Local                        True        25h</span><br><span class="line">v1.authentication.k8s.io               Local                        True        25h</span><br><span class="line">v1.authorization.k8s.io                Local                        True        25h</span><br><span class="line">v1.autoscaling                         Local                        True        25h</span><br><span class="line">v1.batch                               Local                        True        25h</span><br><span class="line">v1.coordination.k8s.io                 Local                        True        25h</span><br><span class="line">v1.networking.k8s.io                   Local                        True        25h</span><br><span class="line">v1.rbac.authorization.k8s.io           Local                        True        25h</span><br><span class="line">v1.scheduling.k8s.io                   Local                        True        25h</span><br><span class="line">v1.storage.k8s.io                      Local                        True        25h</span><br><span class="line">v1beta1.admissionregistration.k8s.io   Local                        True        25h</span><br><span class="line">v1beta1.apiextensions.k8s.io           Local                        True        25h</span><br><span class="line">v1beta1.authentication.k8s.io          Local                        True        25h</span><br><span class="line">v1beta1.authorization.k8s.io           Local                        True        25h</span><br><span class="line">v1beta1.batch                          Local                        True        25h</span><br><span class="line">v1beta1.certificates.k8s.io            Local                        True        25h</span><br><span class="line">v1beta1.coordination.k8s.io            Local                        True        25h</span><br><span class="line">v1beta1.discovery.k8s.io               Local                        True        25h</span><br><span class="line">v1beta1.events.k8s.io                  Local                        True        25h</span><br><span class="line">v1beta1.extensions                     Local                        True        25h</span><br><span class="line">v1beta1.metrics.k8s.io                 kube-system/metrics-server   True        56m</span><br><span class="line">v1beta1.networking.k8s.io              Local                        True        25h</span><br><span class="line">v1beta1.node.k8s.io                    Local                        True        25h</span><br><span class="line">v1beta1.policy                         Local                        True        25h</span><br><span class="line">v1beta1.rbac.authorization.k8s.io      Local                        True        25h</span><br><span class="line">v1beta1.scheduling.k8s.io              Local                        True        25h</span><br><span class="line">v1beta1.storage.k8s.io                 Local                        True        25h</span><br><span class="line">v2beta1.autoscaling                    Local                        True        25h</span><br><span class="line">v2beta2.autoscaling                    Local                        True        25h</span><br></pre></td></tr></table></figure>

<p>6.配置弹性伸缩 编写 deployment-nginx-hpa.yaml 文件，要求最小副本数 1，最大副本数 3， 当整体的资源利用率超过 80%的时候实现自动扩容，将 yaml 文件提交至答题框。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# cat deployment-nginx-hpa.yaml </span><br><span class="line">apiVersion: autoscaling/v2</span><br><span class="line">kind: HorizontalPodAutoscaler</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-hpa</span><br><span class="line">spec:</span><br><span class="line">  scaleTargetRef:</span><br><span class="line">    apiVersion: apps/v1</span><br><span class="line">    kind: Deployment</span><br><span class="line">    name: nginx</span><br><span class="line">  minReplicas: 1</span><br><span class="line">  maxReplicas: 3</span><br><span class="line">  targetCPUUtilizationPercentage: 80</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# kubectl apply -f deployment-nginx-hpa.yaml</span><br><span class="line">[root@master ~]# kubectl get hpa</span><br><span class="line">NAME        REFERENCE              TARGETS   MINPODS   MAXPODS   REPLICAS   AGE</span><br><span class="line">nginx-hpa   Deployment/nginx-hpa   0%/80%    1         3         1          159m</span><br></pre></td></tr></table></figure>

<p>7.压力测试 安装 httpd-tools 工具，通过 service 提供的对外访问接口进行压力测试， 验证 HPA 弹性伸缩功能，将 HPA 状态和 POD 状态截图提交至答题框。【2 分】</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# yum install -y httpd-tools</span><br><span class="line">[root@master ~]# kubectl get pods -o wide</span><br><span class="line">NAME                                    READY   STATUS    RESTARTS   AGE   IP            NODE     NOMINATED NODE   READINESS GATES</span><br><span class="line">nfs-client-provisioner-8d5b467d-5cl8s   1/1     Running   6          23h   10.244.1.3    node1    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">nginx-665b4cdfdd-48hwn                  1/1     Running   0          23h   10.244.2.2    node2    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">nginx-hpa-78c58b9df7-qjdhh              1/1     Running   2          22h   10.244.0.14   master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">[root@master ~]# ab -t 600 -n 1000000 -c 1000 http://10.244.0.14/path</span><br><span class="line">[root@master ~]# kubectl get hpa</span><br><span class="line">NAME        REFERENCE              TARGETS   MINPODS   MAXPODS   REPLICAS   AGE</span><br><span class="line">nginx-hpa   Deployment/nginx-hpa   0%/80%    1         3         1          162m</span><br></pre></td></tr></table></figure>


      
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2022/09/19/%E9%87%91%E7%A0%96%E5%9B%BD%E8%B5%9B%E6%A0%B7%E9%A2%98%E4%B8%89/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">&lt;</strong>
      <div class="article-nav-title">
        
          金砖国赛样题三
        
      </div>
    </a>
  
  
    <a href="/2022/09/02/%E9%87%91%E7%A0%96%E5%9B%BD%E8%B5%9B%E6%A0%B7%E9%A2%98%E4%B8%80/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">金砖国赛样题</div>
      <strong class="article-nav-caption">&gt;</strong>
    </a>
  
</nav>

  
</article>






</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
      <div class="footer-left">
        &copy; 2023 Miss
      </div>
        <div class="footer-right">
          <a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/preccrep/hexo-theme-jelly" target="_blank">Jelly</a>
        </div>
    </div>
  </div>
</footer>
    </div>
    
  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">



<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: false,
		animate: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>

<script src="/js/main.js"></script>




  </div>
</body>
</html>